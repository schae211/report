---
title: 1. Introduction
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: yes
    toc_float: no
bibliography: references.bib
csl: science.csl
link-citations: yes
---

<style>
body {
text-align: justify;
margin: 300px}
</style>

In recent years the field of single-cell biology has vastly expanded. Since the publication of Drop-seq[@10.1016/j.cell.2015.05.002] in 2015, the number of studies based on single-cell omics has exploded, primarily due to the  commercialization of microfluidics-based single-cell sequencing by 10X Genomics. However, this technology requires a single-cell suspension, meaning tissues must be dissociated before being analyzed. Consequently, we loose information about the spatial context of cells, which is crucial for their function. Cells use different mechanisms to exchange information such as juxtacrine signaling via membrane-bound ligands or paracrine signaling via secreted ligands. Thereby, most communication mechanisms are limited to the neighborhood of a given cell due to dilution of signals by diffusion or the requirement of direct cell-to-cell contact. Therefore, inferring the interaction of different proteins or more broadly cell-cell communication (CCC) using single-cell expression data from dissociated tissues is difficult. Consequently, knowing about the position of single cells should help to infer interactions. 

The required multiplexed spatially resolved data only became available in recent years. Below, I will briefly describe new spatially resolved transcriptomic (1.1) and proteomic approaches (1.2) based on these reviews [@Moses2021.05.11.443152; @10.3389/fimmu.2019.02657]. Apart from the data, adequate analysis frameworks and tools are needed to gain biological insights. Most approaches focus on visualization of the data, finding spatially variable genes/gene programs, or cellular niches. However, few tools aim to decipher which factors/features in/of the cellular environment could drive the expression of certain genes/proteins. MISTy, an analysis framework based on explanatory machine learning, has been developed by Tanevski et al. [@Tanevski2020.05.08.084145] to tackle this question. Given a marker (gene/protein), the user defines predictors based on the spatial context (hereafter called views). For example, a view could comprise the expression of all other markers in the direct neighborhood (juxtaview). For example given the expression of our marker A in a certain cell, can this expression be predicted using the expression of marker B and C in the neighboring cells. Each of these views is modeled with a random forest model, and all these view-specific models are then combined in a meta model via ridge regression (the model will be described in more detail below). In this work, the framework was generalized in such a way, that the view-specific models can now be build using any user-supplied machine learning algorithm. Thus, allowing users to choose the best algorithm for the task at hand in the spirit of the "no free lunch theorem" (which describes that there is no single model that works optimally for all tasks). I will further describe MISTy and other tools to analyze spatial omics data below (1.3).

# 1.1 Spatial Transcriptomics

Modern spatial transcriptomic approaches can be broadly classified into four categories, namely microdissection, single-molecule fluorescent in-situ hybridization (smFISH), in-situ sequencing (ISS), and spatial barcoding in conjunction with next-generation sequencing (NGS). Microdissection refers to a couple of methods for isolating small regions of interest which can subsequently be analyzed (for example by NGS). Advantages are the flexibility with respect to the size of the isolated spots (e.g. down to the size of nuclei) and with respect to the downstream analysis, and the compatibility with FFPE tissues. However, this comes at the cost of being laborious due to sequential handling of the isolated spots. Thus, the throughput, meaning how many cells/spots can be processed in a given time, is much higher for the other methods. In particular spatial barcoding with NGS offers a high throughput due to its commercialization by 10X Genomics ("Visium") and standard downstream pipelines of NGS data (demultiplexing, alignment, etc.). 

Visium is based on slides containing spots coated with capture sequences comprising a sequencing handle, barcode, UMI, and poly-T. The tissue is added on top of the slide and permeabilized, such that the polyadenylated transcripts bind to the capture sequences. Being based on NGS, these methods cover the whole transcriptome, which comes at the expense of a low resolution (corresponding to the size of the spots). 

Both smFISH and ISS have single-cell (or even subcellular) resolution. Two common methods for smFISH are seqFISH [@10.1016/j.neuron.2016.10.001] and MERFISH [@10.1073/pnas.1612826113]. They are both based on multiple rounds of hybridization. seqFISH uses unique sequences of colors in each hybridization round to identify transcripts (i.e. in each round a transcript is labeled with multiple probes containing the same fluorophore). MERFISH uses transcript specific encoding probes which can be bound by fluorescently labeled readout probes which always have the some color. By construction, a readout probe binds or does not bind a given transcript in a given hybridization round, creating a binary code of the same length as the number of hybridzation rounds. So each transcript is encoded by a unique binary code. By choosing a Hamming distance larger than one, this approach helps to reduce detection errors. Usually both methods cover around 300 different transcripts, but can be scaled up to cover many more genes (usually at the cost of including fewer cells). 

The last category of spatial transcriptomic technologies discussed here comprises ISS, which can be divided into sequencing by ligation (SBL) and sequencing by synthesis (SBS). Most ISS technolgies, such as the Cartana platform (10X Genomics) are based on SBL. The specificity of DNA ligation is exploited by padlock probes which can only be ligated if they perfectly bind to reverse transcribed RNAs. Upon ligation the padlock probes are amplified by rolling-circle amplification (RCA) and detected by fluorescence labeling. [@10.1016/j.cell.2020.06.038] Due to RCA signal amplification the imaging can be done at lower magnifications compared to smFISH methods allowing for larger tissue sections to be imaged.

# 1.2 Spatial Proteomics

Apart from spatial transcriptomics, the field of spatial proteomics is also rapidly expanding. Two examples for spatial proteomic technologies are imaging mass cytometry (IMC) [@10.1038/nmeth.2869] and multiplexed ion beam imaging (MIBI) [@10.1038/nm.3488]. Conventional technologies to visualize proteins in tissue sections such as immunohistochemistry (IHC) are based on antibodies conjugated with fluorophores or reporter enzymes, which makes mulitplexing difficult due to spectral overlap. For IHC several rounds of staining, imaging and photobleaching are needed for multiplexing, whereas IMC and MIBI solve this issue by using antibodies conjugated with heavy-metal isotopes which can be detected via mass cytometry imaging. Both technologies can image up to 40 different proteins. MIBI uses an oxygen duoplasmatron ion beam to ionize the heavy-metal labels, whereas IMC uses an UV laser to ablate the tissue which is subsequently atomized and ionized. According to Baharlou H. et al [@10.3389/fimmu.2019.02657], the main differences between the technologies is that the size of the MIBI ion beam and thus the spatial resolution is tunable between 1,000 and 260 nm, whereas the IMC laser is fixed at 1,000 nm. However, IMC has faster acquisition times compared to MIBI.

# 1.3 Data Analysis

No matter which of the above technologies is used, a table containing either the markers for each spatial unit (spot or single cells) or the coordinates of markers (high resolution but no segmentation) is obtained after preprocessing. Following normalization, standard scRNA-seq tools are often used to explore the data. However, as more spatially resolved datasets are being published, new tools are developed to exploit these richer information. There are tool for the detection of spatially variable genes (e.g. SPARK-X [@10.1186/s13059-021-02404-0], SpatialDE [@10.1038/nmeth.4636]), detection of co-expression patterns/gene programs (e.g. ), and the detection of cellular niches (e.g. ). 

Upon identification of interesting patterns in spatially resolved omics data one might ask the question what drives the emergence or stabilizes these patterns? Is the spatial structure driven by self-organization, juxtacrine/ paracrine signaling, or broad gradients of morphogens? Several tools have been published which tackle related questions. Spatial Variance Component Analysis (SVCA) [@10.1016/j.celrep.2019.08.077] for example decomposed the variance of a given marker into an intrinsic, intercellular, and environmental component. However, these spatial contexts are fixed and no information about which interactions can explain the expression of a given marker are learned. 

In contrast, MISTy (Multiview Intercellular SpaTial modeling framework) [@Tanevski2020.05.08.084145] is much more flexible, allowing users to define the spatial context however they want. By default juxtacrine and paracrine views can be composed, which include the direct neighbors of a given cell and the broader tissue environment. Importantly, MISTy is build around an explainable machine learning algorithm facilitating interpretability of the results. This means after training a given model composed of several views, we obtain for each view and for each target marker in the view which other markers are helpful in explaining the expression of the considered marker (hereafter refereed to as importances). The basic MISTy workflow and the primary questions that can be answered are shown below.

So we start by defining certain views. The intraview is usually the baseline view in which we only take intracellular information into account, i.e. we predict the expression of a given marker in a cell using the expression values for all other markers in the same cell (or rather spatial units). Then, we add other views taking the spatial context into consideration, for example the juxtaview in which we predict the expression of a given marker in a cell using the expression of the other markers in the directly neighboring cells, or the paraview in which we use the other markers in the tissue environment weighted by their distances to the considered cell as predictors. The colors in the figure should indicate these weights, which are by default computed via a Gaussian kernel (but other kernels are possible). As indicated in the figure, each view is modeled by a random forest, meaning for each marker in each view, one random forest model in computed. The predictions from each view are combined in a late-fusion meta model based on ridge regression to control for correlated views.

<img src="https://www.dropbox.com/s/jynhjs4hc7k7oye/Slide6.png?raw=1" align="center" width="800">

So first, we can ask for which targets the prediction improves if we take the spatial context into consideration. Therefore, we compare the R2 (fraction of variance explained) of the intra-view model (below in red) and the multi-view model (below in green), which comprises all views.

<img src="https://www.dropbox.com/s/jteucwitjj5cywr/Slide8.png?raw=1" align="center" width="800">

Next we can answer the question how (relatively) important each view is in the the prediction of a given target by comparing the coefficents in the meta model.

<img src="https://www.dropbox.com/s/ad54sbjxw5ue7ea/Slide9.png?raw=1" align="center" width="800">

Exploiting the interpretability of random forest, we can also ask which other markers are important when predicting the expression of a given marker in a given view. These "importances" are weighted by the p-value of the corresponding view in the meta model.

<img src="https://www.dropbox.com/s/9f5kggot1jgwcee/Slide10.png?raw=1" align="center" width="800">

For a given target, there are often large differences in performance measures such as the gain in variance explained (R2). To find out what drives the differences in the results, MISTy signatures can be used. To that end, the results for all views and all targets in each sample are combined into a vector. So each sample has certain coordinates in the results space which can for example be visualized by plotting the first two principal components. Samples that share a certain tissue organisation often cluster together. In the example below, one can clearly see that compartmentalized tumors cluster together.

<img src="https://www.dropbox.com/s/xru4pzsnjwl64so/Slide30.png?raw=1" align="center" width="800">

# 1.4 This Work

In this work, the code base of MISTy was refactored and extended in such a way that different machine learning models apart from random forest can now be used to model each view as indicated in the scheme below. Importantly, the implementation also enables users to provide their own favorite algorithm, making MISTy as flexible as possible.

<img src="https://www.dropbox.com/s/226o7lo8zfxk2dm/implementation.png?raw=1" align="center" width="800">

In the [Methods](https://schae211.github.io/report/tutorial.html) section I will describe this flexible implementation which allows the usage of different machine learning algorithms for training view-specific models in MISTy. Based on the new underlying framework, the function to model each view is now passed as an argument to the `run_misty()` call. The default model is still random forest, but now users can either plug in another provided model function such as gradient boosting or define their own function such as non-negative least-squares. The code below specifies that the `gradient_boosting_model` with trees (`booster = "gbtree"`) should be used to model views.

```{r eval=FALSE}
misty.views %>%
  run_misty(model.function = gradient_boosting_model, 
            booster = "gbtree")
```

<details> <summary>Click here for MISTy flowchart</summary> 
```{r echo=FALSE}
DiagrammeR::grViz('digraph{

      # setting the global strucutre (top to low)
      graph[rankdir = TL]
  
      # setting the default node layout
      node[shape = rectangle, style = filled]
  
      subgraph cluster_1 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = PaleTurquoise
        label = "Input: Spatial Omics"
        node[fillcolor = White, margin = 0.2]
          EXP[label = "expression"]
          POS[label = "positions"]
      }
      
      subgraph cluster_3 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = PaleTurquoise
        label = "Generating Views"
        node[fillcolor = White, margin = 0.2]
        CIV[label = "create_initial_view()"]
        AJV[label = "add_juxtaview()"]
        APV[label = "add_paraview()"]
      }
      
      subgraph cluster_4 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = PaleTurquoise
        label = "MISTy Views"
        node[fillcolor = White, margin = 0.2]
        IV[label = "intraview"]
        JV[label = "juxtaview"]
        PV[label = "paraview"]
        V[label = "misty views"]
      }
      
      subgraph cluster_5 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = PaleTurquoise
        label = "MISTy Parameters"
        node[fillcolor = White, margin = 0.2]
        RES[label = "results.folder"]
        MF[label = "model.function", fillcolor = "Gold"]
        TS[label = "target.subset"]
        CV[label = "cv.folds"]
        BI[label = "bypass.intra"]
        DOTS[label = "..."]
      }
      
      subgraph cluster_6 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = PaleTurquoise
        label = "Output: MISTy Results"
        node[fillcolor = White, margin = 0.2]
          PER[label = "performance"]
          CON[label = "contribution"]
          IMP[label = "importances"]
      }
      
      subgraph cluster_8 {
        graph[shape = rectangle]
        style = rounded
        bgcolor = PaleTurquoise
        label = "Running MISTy"
        node[fillcolor = White, margin = 0.2]
        RM[label = "run_misty()"]
        CR[label = "collect_results()"]
      }
      
      edge[color = black, arrowhead = vee, arrowsize = 0.8]
      EXP -> CIV
      POS -> {APV, AJV}
      CIV -> {APV, AJV}
      CIV -> IV
      APV -> PV
      AJV -> JV
      {IV, PV, JV} -> V
      {V, RES, MF, TS, CV, BI, DOTS} -> RM
      RM -> CR
      CR -> {PER, CON, IMP}
      
}')
```
</details>

In the results section, I will first show [benchmarking](https://schae211.github.io/report/benchmark.html) results, where I compare the performance of different algorithms on different spatial omics datasets. I also explore how the importances differ between the models. Lastly, I show the impact of different hyperparameters on the model performance for the algorithms.

In the [frameworks](https://schae211.github.io/report/frameworks.html) section I briefly describe why we could not use one of the major machine learning frameworks in R, namely `caret`, `tidymodels`, and `mlr3` as back-end in MISTy models. These frameworks are either not flexible enough, or their performance is insufficient.

Also, I will describe an [alternative](https://schae211.github.io/report/model_api.html) implementation of a new MISTy framework that allows users to select more ML models than only random forests, but not to use functions defined by themselves. Running MISTy with an ensemble of 50 MARS models (interaction term 2) trained with bootstrap samples would looks like this.

```{r eval=FALSE}
misty.views %>% 
  run_misty(method = "bag", learner = "earth", 
            n.learners = 50, degree = 2)
```

In the end, I will [discuss](https://schae211.github.io/report/model_api.html) the results of my work and pose remaining open questions for the development of MISTy and the field of spatial omics technologies.

---

```{r include=FALSE}
# todo
# 1. Include the Theis model [@Fischer2021.07.11.451750]
```

# References
