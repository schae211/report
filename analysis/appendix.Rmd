---
title: "Overview"
---

Setup.

```{r setup}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE)
```

Loaded packages.

```{r}
suppressPackageStartupMessages(library(mistyR))
suppressPackageStartupMessages(library(future))
suppressPackageStartupMessages(library(tidyverse))
plan("multisession", workers=14)
```

# Appendix

The appendix contains code chunks which were not yet added to the appropriate sections within the report.

Let's create some MISTy views first.

```{r}
data("synthetic")
expr <- synthetic$synthetic1 %>% select(-c(row, col, type))
pos <- synthetic$synthetic1 %>% select(c(row, col))
misty.views <- create_initial_view(expr) %>%
  add_paraview(positions = pos, l = 12, zoi = 0)
```

## Effect of Subsampling on Performance

The possibility for subsampling the training set was introduced to 
reduce the training time, since MISTy is often applied to large
datasets where the modelling of each view should not take too long.

Since the approximation only affects the computation of the unbiased 
prediction, we only need to have a look at the performance estimation

### SVM

```{r}
approx.results.svm <- map(seq(0.1, 1, l = 10), function(frac) {
  print(frac)
  misty.views %>%
  run_misty(model.function = svm_model, approx = frac) %>%
  collect_results()
})
```

I guess based on those results a default approximation fraction of **0.4** would 
make sense.

```{r fig.height=6, fig.width=12}
svm.improvements <- map2_dfr(approx.results.svm, 
                             seq(0.1, 1, l = 10), function(misty.results, frac) {
  misty.results$improvements %>% mutate(approx = frac)
})
svm.improvements %>%
  mutate(approx = factor(approx, levels = seq(0.1, 1, l = 10))) %>%
  filter(measure == "multi.R2") %>%
  ggplot() +
  geom_point(aes(x = approx, y = value)) +
  facet_wrap(~ target, scales="free")
```

### NN

```{r}
#tmp
approx <- 0.6
target <- "ECM"
k <- 10
view_data <- misty.views$intraview$data
seed <- 42
ellipsis.args <- list()
```


```{r}
approx.results.nn <- map(seq(0.1, 1, l = 10), function(frac) {
  print(frac)
  misty.views %>%
  run_misty(model.function = mlp_model, approx = frac) %>%
  collect_results()
})
```

I guess based on those results a default approximation fraction of **0.6** would 
make sense.

```{r fig.height=6, fig.width=12}
nn.improvements <- map2_dfr(approx.results.nn, 
                             seq(0.1, 1, l = 10), function(misty.results, frac) {
  misty.results$improvements %>% mutate(approx = frac)
})
nn.improvements %>%
  mutate(approx = factor(approx, levels = seq(0.1, 1, l = 10))) %>%
  filter(measure == "multi.R2") %>%
  ggplot() +
  geom_point(aes(x = approx, y = value)) +
  facet_wrap(~ target, scales="free")
```

## Overfitting the NN Function

```{r}
sizes = list("5" = c(5), "10" = c(10), "2x10" = c(10, 10), "3x10" = c(10, 10, 10),
             "3x16" = c(16, 16, 16))
overfit.nn.results <- map(sizes, function(s) {
  print(s)
  misty.views %>%
  run_misty(model.function = mlp_model, approx = 0.6,
            size = s) %>%
  collect_results()
})
```

And we basically see that the landscape is highly heterogeneous depending
on the target. Sometimes a more complex model is helpful and sometimes not! 

```{r fig.height=6, fig.width=12}
overfit.nn.impro <- map2_dfr(overfit.nn.results, 
                             names(sizes), function(misty.results, s) {
  misty.results$improvements %>% mutate(size = s)
})
overfit.nn.impro %>%
  filter(measure == "multi.R2") %>%
  mutate(size = factor(size, levels = names(sizes))) %>%
  ggplot() +
  geom_point(aes(x = size, y = value)) +
  facet_wrap(~ target, scales="free")
```
